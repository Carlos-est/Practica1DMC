{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import practica1 as p1\n",
    "texto = \"This code treats each word as an individual character rather than tokenizing the text into words. If you need to tokenize the text before removing stopwords, you might want to incorporate a tokenization function such as word_tokenize from NLTK.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos el texto en tokens\n",
    "doc = p1.tokenize_text(texto)\n",
    "#print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'code', 'treats', 'each', 'word', 'as', 'an', 'individual', 'character', 'rather', 'than', 'tokenizing', 'the', 'text', 'into', 'words', '.', 'If', 'you', 'need', 'to', 'tokenize', 'the', 'text', 'before', 'removing', 'stopwords', ',', 'you', 'might', 'want', 'to', 'incorporate', 'a', 'tokenization', 'function', 'such', 'as', 'word_tokenize', 'from', 'NLTK', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# remover stopwords\n",
    "doc_stop = p1.remove_stopwords(doc)\n",
    "print(doc_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'codir', 'treats', 'each', 'word', 'as', 'an', 'individual', 'character', 'rather', 'thaber', 'tokenizing', 'the', 'text', 'into', 'words', '.', 'If', 'you', 'need', 'to', 'tokenize', 'the', 'text', 'before', 'removing', 'stopwords', ',', 'you', 'might', 'want', 'to', 'incorporatir', 'a', 'tokenization', 'function', 'such', 'as', 'word_tokenize', 'from', 'NLTK', '.']\n"
     ]
    }
   ],
   "source": [
    "# lematizacion\n",
    "doc_lema = p1.lematizacion_text(texto)\n",
    "print(doc_lema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# stemming\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m doc_stem \u001b[38;5;241m=\u001b[39m p1\u001b[38;5;241m.\u001b[39mstemming_text(texto)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc_stem)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\OneDrive\\Documentos\\carlos\\DEM PERU\\clase 2\\codigos\\practica1\\practica1.py:20\u001b[0m, in \u001b[0;36mstemming_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstemming_text\u001b[39m(text):\n\u001b[0;32m     19\u001b[0m     stemmer \u001b[38;5;241m=\u001b[39m SnowballStemmer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspanish\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     doc_stemming \u001b[38;5;241m=\u001b[39m [stemmer\u001b[38;5;241m.\u001b[39mstem(token\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m text]\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc_stemming\n",
      "File \u001b[1;32mc:\\Users\\carlo\\OneDrive\\Documentos\\carlos\\DEM PERU\\clase 2\\codigos\\practica1\\practica1.py:20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstemming_text\u001b[39m(text):\n\u001b[0;32m     19\u001b[0m     stemmer \u001b[38;5;241m=\u001b[39m SnowballStemmer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspanish\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     doc_stemming \u001b[38;5;241m=\u001b[39m [stemmer\u001b[38;5;241m.\u001b[39mstem(token\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m text]\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc_stemming\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "doc_stem = p1.stemming_text(texto)\n",
    "print(doc_stem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
